import torch
import nodes

class SF_ActionAnimator:
    """
    Convierte una composici칩n est치tica en un flujo de video (Latent Batch).
    Aplica 'Movement Restriction' usando la m치scara para garantizar que el fondo no tiemble.
    """
    def __init__(self):
        pass

    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "vae": ("VAE",),                # Necesario para codificar la imagen a Latent
                "composed_image": ("IMAGE",),   # La imagen del SceneComposer
                "fusion_mask": ("MASK",),       # La m치scara del SceneComposer
                "frame_count": ("INT", {"default": 24, "min": 8, "max": 120, "step": 8}),
                "motion_freedom": ("FLOAT", {"default": 1.0, "min": 0.1, "max": 1.0, "step": 0.1}),
            }
        }

    RETURN_TYPES = ("LATENT",)
    RETURN_NAMES = ("video_latents",)
    FUNCTION = "prepare_action"
    CATEGORY = "游빌 Studio Fury/游꿟 Director"

    def prepare_action(self, vae, composed_image, fusion_mask, frame_count, motion_freedom):
        # 1. Codificaci칩n VAE (De P칤xeles a Latents)
        # Usamos el VAE Encode est치ndar pero internamente
        # composed_image shape: [1, H, W, 3]

        # Necesitamos asegurarnos de que la imagen tiene el formato correcto para el VAE
        # El VAE espera [B, C, H, W] en algunos contextos internos, pero el nodo standard VAEEncode usa la imagen tal cual.
        # Invocamos la l칩gica de codificaci칩n:
        t = vae.encode(composed_image[:,:,:,:3])
        original_latent = t.to(composed_image.device) # [1, 4, H/8, W/8]

        # 2. Expansi칩n Temporal (Crear el "Film Strip")
        # Repetimos el latent est치tico tantas veces como frames queramos
        # Esto crea un video donde, por ahora, todos los frames son iguales.
        video_latents = original_latent.repeat(frame_count, 1, 1, 1)

        # 3. Preparaci칩n de la M치scara de Movimiento
        # La m치scara viene como [1, H, W]. Necesitamos bajarla a la resoluci칩n del Latent (H/8, W/8)
        mask = fusion_mask.clone()

        # Redimensionar m치scara al tama침o Latent (nearest para mantener bordes duros o bilinear para suaves)
        # Torch espera [Batch, Channels, Height, Width] para interpolar
        mask = mask.unsqueeze(0) # [1, 1, H, W]

        # Calculamos dimensiones del latent
        lat_h = original_latent.shape[2]
        lat_w = original_latent.shape[3]

        mask_resized = torch.nn.functional.interpolate(
            mask, size=(lat_h, lat_w), mode="bilinear", align_corners=False
        )

        # 4. Aplicar "Motion Freedom" (Libertad de Movimiento)
        # Si la m치scara es blanca (1.0), el personaje se mueve.
        # Si es negra (0.0), el fondo est치 bloqueado.
        # 'motion_freedom' puede hacer que el 치rea "permitida" sea un poco m치s gris si queremos restringir
        mask_resized = mask_resized * motion_freedom

        # Aplanar para formato de m치scara de Comfy [Batch, H, W] (sin canales)
        mask_final = mask_resized.squeeze(1)

        # Repetir la m치scara para cada frame del video
        mask_batch = mask_final.repeat(frame_count, 1, 1)

        # 5. Inyectar la m치scara en el Latent
        # ComfyUI usa una estructura de diccionario para los latents
        output_latent = {
            "samples": video_latents,
            "noise_mask": mask_batch # Aqu칤 est치 el secreto del control absoluto
        }

        return (output_latent,)

NODE_CLASS_MAPPINGS = {
    "SF_ActionAnimator": SF_ActionAnimator
}

NODE_DISPLAY_NAME_MAPPINGS = {
    "SF_ActionAnimator": "游꿟 SF Action Animator (Latent Prep)"
}