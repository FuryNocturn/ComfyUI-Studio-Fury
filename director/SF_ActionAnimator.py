import torch

class SF_ActionAnimator:
    """
    Convierte una composici칩n est치tica en un flujo de video (Latent Batch).
    Aplica 'Movement Restriction' usando la m치scara para garantizar que el fondo no tiemble.
    """
    def __init__(self):
        pass

    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "vae": ("VAE",),                # Necesario para codificar la imagen a Latent
                "composed_image": ("IMAGE",),   # La imagen del SceneComposer
                "fusion_mask": ("MASK",),       # La m치scara del SceneComposer
                "frame_count": ("INT", {"default": 24, "min": 8, "max": 120, "step": 8}),
                "motion_freedom": ("FLOAT", {"default": 1.0, "min": 0.1, "max": 1.0, "step": 0.1}),
            }
        }

    RETURN_TYPES = ("LATENT",)
    RETURN_NAMES = ("video_latents",)
    FUNCTION = "prepare_action"
    CATEGORY = "游빌 Studio Fury/游꿟 Director"

    def prepare_action(self, vae, composed_image, fusion_mask, frame_count, motion_freedom):
        # 1. Codificaci칩n VAE (De P칤xeles a Latents)
        # ComfyUI espera [Batch, H, W, C]
        # VAE Encode output -> {"samples": tensor}

        print(f"游꿟 [Animator] Codificando {frame_count} frames...")

        # Codificamos la imagen compuesta
        encoded = vae.encode(composed_image[:,:,:,:3]) # Asegurar 3 canales
        original_latent = encoded["samples"] # [1, 4, H/8, W/8]

        # 2. Repetici칩n temporal (Batch Repeat)
        # Convertimos 1 imagen est치tica en N frames id칠nticos
        video_latents = original_latent.repeat(frame_count, 1, 1, 1)

        # 3. Procesamiento de la M치scara
        # La m치scara viene como [H, W] o [1, H, W]
        mask = fusion_mask
        if len(mask.shape) == 2:
            mask = mask.unsqueeze(0)

        # Escalar m치scara al tama침o del latent (1/8)
        # Necesitamos [1, 1, H, W] para interpolaci칩n
        mask_tensor = mask.unsqueeze(0)

        # Dimensiones objetivo
        lat_h = original_latent.shape[2]
        lat_w = original_latent.shape[3]

        mask_resized = torch.nn.functional.interpolate(
            mask_tensor, size=(lat_h, lat_w), mode="bilinear", align_corners=False
        )

        # Quitar dimensiones extra -> [1, H, W]
        mask_resized = mask_resized.squeeze(0)

        # 4. Aplicar "Motion Freedom"
        # 1.0 = Movimiento total donde hay m치scara.
        # 0.0 = Congelado.
        mask_final = mask_resized * motion_freedom

        # Repetir m치scara para cada frame
        mask_batch = mask_final.repeat(frame_count, 1, 1)

        # 5. Salida en formato Latent de ComfyUI
        # Inyectamos la 'noise_mask'. Los samplers de video (AnimateDiff) la usan
        # para saber qu칠 p칤xeles deben cambiar y cu치les dejar quietos.
        output_latent = {
            "samples": video_latents,
            "noise_mask": mask_batch
        }

        return (output_latent,)

# --- REGISTRO DEL NODO ---
NODE_CLASS_MAPPINGS = {
    "SF_ActionAnimator": SF_ActionAnimator
}
NODE_DISPLAY_NAME_MAPPINGS = {
    "SF_ActionAnimator": "游끢 SF Action Animator"
}